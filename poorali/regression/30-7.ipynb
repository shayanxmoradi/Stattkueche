{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "######################################################################\n",
    "# 1. Load\n",
    "######################################################################\n",
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "DATA_PATH = Path('/content/4class.csv')\n",
    "assert DATA_PATH.exists(), f\"{DATA_PATH} not foundâ€”upload it first.\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"âœ… raw: {df.shape[0]:,} rows Ã— {df.shape[1]} cols\")\n",
    "\n",
    "######################################################################\n",
    "# 2. Leakage & ID removal\n",
    "######################################################################\n",
    "df = df.drop(columns=[\n",
    "    c for c in [\"DateOfCancel\",\"CanceledQty\",\"net_qty\",\"days_to_cancel\",\n",
    "                \"Unnamed: 0\",\"TransactionId\",\"BookingNr\",\"OrderId\"]\n",
    "    if c in df.columns])\n",
    "print(\"Remaining after leakage/ID purge:\", df.shape[1])\n",
    "\n",
    "######################################################################\n",
    "# 3. Feature engineering\n",
    "######################################################################\n",
    "df[\"DateOfOrder\"]   = pd.to_datetime(df[\"DateOfOrder\"])\n",
    "df[\"DateOfService\"] = pd.to_datetime(df[\"DateOfService\"])\n",
    "df[\"lead_time\"]     = (df[\"DateOfService\"] - df[\"DateOfOrder\"]).dt.days.clip(lower=0)\n",
    "\n",
    "srv = df[\"DateOfService\"]\n",
    "df[\"srv_year\"]        = srv.dt.year\n",
    "df[\"srv_month\"]       = srv.dt.month\n",
    "df[\"srv_dayofmonth\"]  = srv.dt.day\n",
    "df[\"srv_weekday\"]     = srv.dt.weekday\n",
    "df[\"srv_is_weekend\"]  = srv.dt.weekday.isin([5,6]).astype(int)\n",
    "\n",
    "df[\"price_paid\"] = df[\"MenuPrice\"] - df[\"MenuSubsidy\"]\n",
    "df = df.drop(columns=[\"DateOfOrder\",\"DateOfService\"])\n",
    "\n",
    "######################################################################\n",
    "# 4. Trim low info columns\n",
    "######################################################################\n",
    "miss_pct = df.isna().mean()\n",
    "df = df.drop(columns=miss_pct[miss_pct>0.30].index)\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "num_df   = df.select_dtypes(include=[np.number]).fillna(0)\n",
    "keep     = VarianceThreshold(0.01).fit(num_df).get_support()\n",
    "df = df.drop(columns=list(set(num_df.columns)-set(num_df.columns[keep])))\n",
    "print(\"Final working columns:\", df.shape[1])\n",
    "\n",
    "######################################################################\n",
    "# 5. Order level classification\n",
    "######################################################################\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose  import ColumnTransformer\n",
    "from sklearn.pipeline  import Pipeline\n",
    "from sklearn.metrics   import classification_report, confusion_matrix\n",
    "from category_encoders import TargetEncoder\n",
    "import lightgbm as lgb\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "y = df[\"cancel_timing\"]\n",
    "X = df.drop(columns=[\"cancel_timing\"])\n",
    "\n",
    "# â”€â”€ 5% FOR TEST â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.05, stratify=y, random_state=42)\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.20, stratify=y_temp, random_state=42)\n",
    "\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = sorted(list(set(X.columns) - set(num_cols)))\n",
    "cat_idx  = [X.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "print(\"\\nBefore SMOTE:\", y_tr.value_counts())\n",
    "\n",
    "smote = SMOTENC(\n",
    "    categorical_features=cat_idx,\n",
    "    sampling_strategy=\"not majority\",\n",
    "    random_state=42\n",
    ")\n",
    "X_tr_bal, y_tr_bal = smote.fit_resample(X_tr, y_tr)\n",
    "\n",
    "print(\"After  SMOTE:\", pd.Series(y_tr_bal).value_counts())\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\",\"passthrough\",num_cols),\n",
    "    (\"cat\",TargetEncoder(handle_missing=\"value\",min_samples_leaf=20),cat_cols)],\n",
    "    verbose_feature_names_out=False)\n",
    "\n",
    "clf = lgb.LGBMClassifier(\n",
    "    objective=\"multiclass\", n_estimators=800, learning_rate=0.05,\n",
    "    num_leaves=64, subsample=0.8, colsample_bytree=0.8,\n",
    "    class_weight=\"balanced\", min_gain_to_split=0.001, random_state=42)\n",
    "\n",
    "pipe_cls = Pipeline([(\"prep\",pre),(\"clf\",clf)]).fit(X_tr_bal, y_tr_bal)\n",
    "\n",
    "print(\"\\n=== Validation set ===\")\n",
    "pred_val = pipe_cls.predict(X_val)\n",
    "print(classification_report(y_val, pred_val))\n",
    "\n",
    "print(\"\\n=== FINAL Test set (5â€¯%) ===\")\n",
    "pred_test = pipe_cls.predict(X_test)\n",
    "print(classification_report(y_test, pred_test))\n",
    "\n",
    "cm = confusion_matrix(y_val, pred_val, labels=pipe_cls.classes_)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=pipe_cls.classes_, yticklabels=pipe_cls.classes_)\n",
    "plt.title(\"Confusion Matrix (validation)\"); plt.xlabel(\"Pred\"); plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "import shap\n",
    "\n",
    "try:\n",
    "    X_val_enc = pipe_cls[\"prep\"].transform(X_val)\n",
    "    shap.summary_plot(\n",
    "        shap.TreeExplainer(pipe_cls[\"clf\"])(X_val_enc, check_additivity=False),\n",
    "        feature_names=pipe_cls[\"prep\"].get_feature_names_out(),\n",
    "        show=False)\n",
    "    plt.title(\"SHAP â€“ order level\"); plt.show()\n",
    "except Exception as e:\n",
    "    print(\"SHAP skipped:\", e)\n",
    "\n",
    "######################################################################\n",
    "# 6. Group daily Poisson regression\n",
    "######################################################################\n",
    "df[\"is_cancel\"] = (df[\"cancel_timing\"]!=\"no_cancel\").astype(int)\n",
    "\n",
    "agg_dict = {\n",
    "    \"order_cnt\":  (\"is_cancel\",\"size\"),\n",
    "    \"cancel_cnt\": (\"is_cancel\",\"sum\"),\n",
    "}\n",
    "\n",
    "for col, fn in {\n",
    "        \"lead_time\":\"mean\", \"price_paid\":\"mean\",\n",
    "        \"tavg_C\":\"mean\", \"prcp_mm\":\"mean\",\"temp_dev\":\"mean\",\"is_holiday\":\"max\"}.items():\n",
    "    if col in df.columns:\n",
    "        agg_dict[f\"{col}_{fn}\"] = (col, fn)\n",
    "\n",
    "print(\"\\nAggregating with cols:\", list(agg_dict.keys()))\n",
    "\n",
    "grp_keys = [\"Site\",\"MenuName\",\"srv_year\",\"srv_month\",\"srv_dayofmonth\"]\n",
    "agg_df = df.groupby(grp_keys, as_index=False).agg(**agg_dict)\n",
    "\n",
    "y_r  = agg_df[\"cancel_cnt\"]\n",
    "X_r  = agg_df.drop(columns=\"cancel_cnt\")\n",
    "mask = ((X_r[\"srv_year\"]<2023) | ((X_r[\"srv_year\"]==2023)&(X_r[\"srv_month\"]<=6)))\n",
    "X_tr_r, X_val_r_orig, y_tr_r, y_val_r_orig = X_r[mask], X_r[~mask], y_r[mask], y_r[~mask]\n",
    "\n",
    "X_val_r, X_test_r, y_val_r, y_test_r = train_test_split(\n",
    "    X_val_r_orig, y_val_r_orig, test_size=0.05, random_state=42)\n",
    "\n",
    "num_cols_r = X_r.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols_r = sorted(list(set(X_r.columns)-set(num_cols_r)))\n",
    "\n",
    "pre_r = ColumnTransformer([\n",
    "    (\"num\",\"passthrough\",num_cols_r),\n",
    "    (\"cat\",TargetEncoder(handle_missing=\"value\",min_samples_leaf=10),cat_cols_r)],\n",
    "    verbose_feature_names_out=False)\n",
    "\n",
    "reg = lgb.LGBMRegressor(\n",
    "    objective=\"poisson\", n_estimators=600, learning_rate=0.05,\n",
    "    num_leaves=64, subsample=0.8, colsample_bytree=0.8,\n",
    "    min_gain_to_split=0.001, random_state=42)\n",
    "\n",
    "pipe_reg = Pipeline([(\"prep\",pre_r),(\"reg\",reg)]).fit(X_tr_r, y_tr_r)\n",
    "pred_val_r = pipe_reg.predict(X_val_r).clip(min=0)\n",
    "pred_test_r = pipe_reg.predict(X_test_r).clip(min=0)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "mae  = mean_absolute_error(y_val_r, pred_val_r)\n",
    "rmse = np.sqrt(mean_squared_error(y_val_r, pred_val_r))\n",
    "r2   = r2_score(y_val_r, pred_val_r)\n",
    "\n",
    "mae_t  = mean_absolute_error(y_test_r, pred_test_r)\n",
    "rmse_t = np.sqrt(mean_squared_error(y_test_r, pred_test_r))\n",
    "r2_t   = r2_score(y_test_r, pred_test_r)\n",
    "\n",
    "print(\"\\n=== Validation (group daily) ===\")\n",
    "print(f\"MAE: {mae:.4f} | RMSE: {rmse:.4f} | RÂ²: {r2:.4f}\")\n",
    "\n",
    "print(\"\\n=== FINAL Test (group daily, 5â€¯%) ===\")\n",
    "print(f\"MAE: {mae_t:.4f} | RMSE: {rmse_t:.4f} | RÂ²: {r2_t:.4f}\")\n",
    "\n",
    "try:\n",
    "    X_val_r_enc = pipe_reg[\"prep\"].transform(X_val_r)\n",
    "    shap.summary_plot(\n",
    "        shap.TreeExplainer(pipe_reg[\"reg\"])(X_val_r_enc, check_additivity=False),\n",
    "        feature_names=pipe_reg[\"prep\"].get_feature_names_out(),\n",
    "        show=False)\n",
    "    plt.title(\"SHAP â€“ group daily\"); plt.show()\n",
    "except Exception as e:\n",
    "    print(\"SHAP skipped:\", e)\n",
    "\n",
    "######################################################################\n",
    "# 7. Save cleaned datasets\n",
    "######################################################################\n",
    "order_out = Path(\"/content/4class_order_clean.csv\")\n",
    "group_out = Path(\"/content/4class_group_daily.csv\")\n",
    "df.drop(columns=\"is_cancel\").to_csv(order_out, index=False)\n",
    "agg_df.to_csv(group_out, index=False)\n",
    "print(f\"ðŸ“ Saved order level CSV â†’ {order_out}\")\n",
    "print(f\"ðŸ“ Saved group daily CSV â†’ {group_out}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

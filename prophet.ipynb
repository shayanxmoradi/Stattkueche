{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-01T07:43:53.354520Z",
     "start_time": "2025-06-01T07:43:53.347214Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T07:46:15.600337Z",
     "start_time": "2025-06-01T07:46:15.574320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_dir = 'results'\n",
    "snapshot_dir = os.path.join(results_dir, 'snapshots')\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    print(f\"Created directory: {results_dir}\")\n",
    "if not os.path.exists(snapshot_dir):\n",
    "    os.makedirs(snapshot_dir)\n",
    "    print(f\"Created directory: {snapshot_dir}\")\n",
    "print(\"-\" * 50)\n"
   ],
   "id": "6fbf78a7de27498f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: results\n",
      "Created directory: results/snapshots\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T08:01:25.721038Z",
     "start_time": "2025-06-01T08:01:09.537371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = 'venvx/AnnonymData.csv'\n",
    "rows_for_snapshot = 1000\n",
    "try:\n",
    "    # For large files, be mindful of memory.\n",
    "    # We'll load it directly for now, but consider 'chunksize' or 'dtype' optimization if needed.\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Successfully loaded data from '{file_path}'.\")\n",
    "    print(f\"Dataset shape: {df.shape}\") # (rows, columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    snapshot1_path = os.path.join(snapshot_dir, 'snapshot_1_raw_loaded_dataset.html')\n",
    "    df.head(rows_for_snapshot).to_html(snapshot1_path, escape=False, index=False) # escape=False for cleaner HTML, index=False to not write pandas index\n",
    "    print(f\"\\nSnapshot 1: First {rows_for_snapshot} rows of the raw loaded dataset saved to '{snapshot1_path}'\")\n",
    "\n",
    "\n",
    "    print(\"\\nFirst 5 rows of the dataset:\")\n",
    "    print(df.head())\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\nDataset info:\")\n",
    "    df.info(verbose=True, show_counts=True)\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at '{file_path}'. Please check the path and filename.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during data loading: {e}\")\n",
    "    exit()\n",
    "print(\"-\" * 50)"
   ],
   "id": "9ebe4bee89b7866f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from 'venvx/AnnonymData.csv'.\n",
      "Dataset shape: (6538739, 14)\n",
      "\n",
      "Snapshot 1: First 1000 rows of the raw loaded dataset saved to 'results/snapshots/snapshot_1_raw_loaded_dataset.html'\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "    OrderId                     TransactionId DateOfService  \\\n",
      "0  11518978  4c5060636f584ef9a1effa77282755f5    2020-01-02   \n",
      "1  11285143  68472c70b9c84fb784834ecc257827d7    2020-01-02   \n",
      "2  11285146  7262eace0d104592b1269e38f5b45ec1    2020-01-02   \n",
      "3  11285152  8e451931e8fc4554869c3e4533b65e23    2020-01-02   \n",
      "4  11285155  bfa8fa0812ee40baa98e5aaf52d30e0b    2020-01-02   \n",
      "\n",
      "           DateOfOrder  OrderQty                     MenuName MenuPrice  \\\n",
      "0  2020-02-05 11:54:08         1             Mittagessen (Gs)      3,10   \n",
      "1  2019-12-16 10:30:51         1  Smart Eating Buffet (WGrus)      0,00   \n",
      "2  2019-12-16 10:31:33         1  Smart Eating Buffet (WGrus)      2,90   \n",
      "3  2019-12-16 10:32:05         1  Smart Eating Buffet (WGrus)      0,00   \n",
      "4  2019-12-16 10:32:31         1  Smart Eating Buffet (WGrus)      2,90   \n",
      "\n",
      "  MenuSubsidy      BookingNr                       GroupName  CanceledQty  \\\n",
      "0        0,00   349-88220481        xxx3,45€ normal 5T (68€)            0   \n",
      "1        3,50  248-141751492          Steinfurt Abo ermäßigt            0   \n",
      "2        0,60   248-77489928  Westerkappeln Grundschüler Abo            0   \n",
      "3        3,50   248-77558043          Steinfurt Abo ermäßigt            0   \n",
      "4        0,60   248-77420774  Westerkappeln Grundschüler Abo            0   \n",
      "\n",
      "  DateOfCancel Site SchoolID  \n",
      "0          NaN   LP   SCH001  \n",
      "1          NaN   BK   SCH002  \n",
      "2          NaN   BK   SCH002  \n",
      "3          NaN   BK   SCH002  \n",
      "4          NaN   BK   SCH002  \n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6538739 entries, 0 to 6538738\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count    Dtype \n",
      "---  ------         --------------    ----- \n",
      " 0   OrderId        6538739 non-null  int64 \n",
      " 1   TransactionId  6538739 non-null  object\n",
      " 2   DateOfService  6538739 non-null  object\n",
      " 3   DateOfOrder    6538739 non-null  object\n",
      " 4   OrderQty       6538739 non-null  int64 \n",
      " 5   MenuName       6538739 non-null  object\n",
      " 6   MenuPrice      6538739 non-null  object\n",
      " 7   MenuSubsidy    6538739 non-null  object\n",
      " 8   BookingNr      6538739 non-null  object\n",
      " 9   GroupName      6538739 non-null  object\n",
      " 10  CanceledQty    6538739 non-null  int64 \n",
      " 11  DateOfCancel   934479 non-null   object\n",
      " 12  Site           5692727 non-null  object\n",
      " 13  SchoolID       6538739 non-null  object\n",
      "dtypes: int64(3), object(11)\n",
      "memory usage: 698.4+ MB\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T07:29:28.806266Z",
     "start_time": "2025-06-01T07:29:26.474506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"--- Step 2: Initial Data Cleaning & Preprocessing ---\")\n",
    "df_processed = df.copy()\n",
    "\n",
    "date_columns = ['DateOfService', 'DateOfOrder', 'DateOfCancel']\n",
    "for col in date_columns:\n",
    "    if col in df_processed.columns:\n",
    "        # Attempt conversion, coercing errors will turn unparseable dates into NaT (Not a Time)\n",
    "        df_processed[col] = pd.to_datetime(df_processed[col], errors='coerce')\n",
    "        print(f\"Column '{col}' converted. NaNs introduced by coercion: {df_processed[col].isnull().sum()}\")\n",
    "    else:\n",
    "        print(f\"Warning: Date column '{col}' not found.\")"
   ],
   "id": "7db983729470c8ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 2: Initial Data Cleaning & Preprocessing ---\n",
      "Column 'DateOfService' converted. NaNs introduced by coercion: 0\n",
      "Column 'DateOfOrder' converted. NaNs introduced by coercion: 0\n",
      "Column 'DateOfCancel' converted. NaNs introduced by coercion: 5604260\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T07:30:17.496144Z",
     "start_time": "2025-06-01T07:30:11.022911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nConverting financial columns ('MenuPrice', 'MenuSubsidy') to numeric...\")\n",
    "financial_columns = ['MenuPrice', 'MenuSubsidy']\n",
    "for col in financial_columns:\n",
    "    if col in df_processed.columns:\n",
    "        if df_processed[col].dtype == 'object': # Only process if it's an object type\n",
    "            # Remove currency symbols (e.g., €, $, £) and commas (as thousands separators)\n",
    "            # This regex is an example, adjust if your currency format is different\n",
    "            df_processed[col] = df_processed[col].astype(str).str.replace(r'[€\\$£,]', '', regex=True)\n",
    "            # Convert to numeric, coercing errors.\n",
    "            # If your numbers use ',' as decimal (e.g., German format), you'd first remove '.', then replace ',' with '.'\n",
    "            df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')\n",
    "            print(f\"Column '{col}' converted to numeric. NaNs introduced: {df_processed[col].isnull().sum()}\")\n",
    "        elif pd.api.types.is_numeric_dtype(df_processed[col]):\n",
    "            print(f\"Column '{col}' is already numeric.\")\n",
    "        else:\n",
    "            print(f\"Column '{col}' is of type {df_processed[col].dtype} and was not processed as a typical currency string.\")\n",
    "    else:\n",
    "        print(f\"Warning: Financial column '{col}' not found.\")"
   ],
   "id": "ee332f452f40ca0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting financial columns ('MenuPrice', 'MenuSubsidy') to numeric...\n",
      "Column 'MenuPrice' converted to numeric. NaNs introduced: 0\n",
      "Column 'MenuSubsidy' converted to numeric. NaNs introduced: 0\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T07:30:44.682136Z",
     "start_time": "2025-06-01T07:30:44.665291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nEnsuring 'OrderQty' and 'CanceledQty' are numeric...\")\n",
    "for col in ['OrderQty', 'CanceledQty']:\n",
    "    if col in df_processed.columns:\n",
    "        if not pd.api.types.is_numeric_dtype(df_processed[col]):\n",
    "            df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')\n",
    "            print(f\"Column '{col}' converted to numeric. NaNs introduced: {df_processed[col].isnull().sum()}\")\n",
    "        else:\n",
    "            print(f\"Column '{col}' is already numeric.\")\n",
    "    else:\n",
    "        print(f\"Warning: Column '{col}' not found.\")"
   ],
   "id": "c9159035998f25b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensuring 'OrderQty' and 'CanceledQty' are numeric...\n",
      "Column 'OrderQty' is already numeric.\n",
      "Column 'CanceledQty' is already numeric.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T07:33:04.134680Z",
     "start_time": "2025-06-01T07:33:03.801834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if 'Site' in df_processed.columns:\n",
    "    missing_site_percentage = df_processed['Site'].isnull().mean() * 100\n",
    "    print(f\"\\nMissing values in 'Site': {missing_site_percentage:.2f}%\")\n",
    "    # Example: df_processed['Site'].fillna('Unknown', inplace=True)\n",
    "    # Or, if you know the main sites are MS, LP, BK, you might investigate if missing sites can be inferred.\n",
    "    # For now, let's fill with 'Unknown' as a placeholder strategy.\n",
    "    df_processed['Site'] = df_processed['Site'].fillna('UnknownSite')\n",
    "    print(\"Filled missing 'Site' values with 'UnknownSite'.\")"
   ],
   "id": "12679da622ba14ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in 'Site': 0.00%\n",
      "Filled missing 'Site' values with 'UnknownSite'.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T07:34:24.837009Z",
     "start_time": "2025-06-01T07:34:22.132844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nFiltering out irrelevant orders...\")\n",
    "initial_rows = len(df_processed)\n",
    "\n",
    "# Condition 1: Orders where DateOfCancel is after DateOfService\n",
    "if 'DateOfCancel' in df_processed.columns and 'DateOfService' in df_processed.columns:\n",
    "    condition1_filter = (df_processed['DateOfCancel'].notna()) & \\\n",
    "                        (df_processed['DateOfService'].notna()) & \\\n",
    "                        (df_processed['DateOfCancel'] > df_processed['DateOfService'])\n",
    "    rows_to_drop_cond1 = df_processed[condition1_filter]\n",
    "    if not rows_to_drop_cond1.empty:\n",
    "        print(f\"Found {len(rows_to_drop_cond1)} orders where DateOfCancel is after DateOfService. These will be dropped.\")\n",
    "        df_processed = df_processed[~condition1_filter]\n",
    "    else:\n",
    "        print(\"No orders found where DateOfCancel is after DateOfService.\")"
   ],
   "id": "8a18505926feec3b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering out irrelevant orders...\n",
      "Found 70970 orders where DateOfCancel is after DateOfService. These will be dropped.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T07:35:19.317250Z",
     "start_time": "2025-06-01T07:35:18.170560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Condition 2: Orders where OrderQty < CanceledQty\n",
    "# Ensure both columns are numeric and handle potential NaNs before comparison\n",
    "if 'OrderQty' in df_processed.columns and 'CanceledQty' in df_processed.columns:\n",
    "    # Fill NaNs with 0 for comparison, assuming NaN in Qty means 0 for this specific filter logic\n",
    "    order_qty_filled = df_processed['OrderQty'].fillna(0)\n",
    "    canceled_qty_filled = df_processed['CanceledQty'].fillna(0)\n",
    "\n",
    "    condition2_filter = order_qty_filled < canceled_qty_filled\n",
    "    rows_to_drop_cond2 = df_processed[condition2_filter]\n",
    "    if not rows_to_drop_cond2.empty:\n",
    "        print(f\"Found {len(rows_to_drop_cond2)} orders where OrderQty < CanceledQty. These will be dropped.\")\n",
    "        df_processed = df_processed[~condition2_filter]\n",
    "    else:\n",
    "        print(\"No orders found where OrderQty < CanceledQty.\")\n",
    "\n",
    "rows_after_filtering = len(df_processed)\n",
    "print(f\"Rows dropped due to filtering: {initial_rows - rows_after_filtering}\")\n",
    "print(f\"Dataset shape after filtering: {df_processed.shape}\")\n"
   ],
   "id": "2206598b7b65abd6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 793547 orders where OrderQty < CanceledQty. These will be dropped.\n",
      "Rows dropped due to filtering: 864517\n",
      "Dataset shape after filtering: (5674222, 14)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T07:36:18.023009Z",
     "start_time": "2025-06-01T07:36:17.035824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# f. Create the Target Variable: `NeededMeals`\n",
    "# NeededMeals = OrderQty - CanceledQty (after filtering and ensuring NaNs in Qty are handled)\n",
    "print(\"\\nCreating the target variable 'NeededMeals'...\")\n",
    "if 'OrderQty' in df_processed.columns and 'CanceledQty' in df_processed.columns:\n",
    "    # Assuming that if CanceledQty is NaN for an order that wasn't filtered out, it means 0 cancellations for that order.\n",
    "    # And if OrderQty is NaN (should be rare after initial checks), treat as 0 for this calculation.\n",
    "    df_processed['OrderQty_filled'] = df_processed['OrderQty'].fillna(0)\n",
    "    df_processed['CanceledQty_filled'] = df_processed['CanceledQty'].fillna(0)\n",
    "\n",
    "    df_processed['NeededMeals'] = df_processed['OrderQty_filled'] - df_processed['CanceledQty_filled']\n",
    "\n",
    "    # Clean up temporary columns\n",
    "    df_processed.drop(columns=['OrderQty_filled', 'CanceledQty_filled'], inplace=True)\n",
    "\n",
    "    print(\"'NeededMeals' column created.\")\n",
    "    print(\"Summary of 'NeededMeals':\")\n",
    "    print(df_processed['NeededMeals'].describe())\n",
    "\n",
    "    # Sanity check: NeededMeals should not be negative if OrderQty < CanceledQty was filtered.\n",
    "    # However, if OrderQty was 0 and CanceledQty was 0, NeededMeals is 0.\n",
    "    # If OrderQty was 0 and CanceledQty was 1 (bank account not covered), this record should have been filtered.\n",
    "    if not df_processed[df_processed['NeededMeals'] < 0].empty:\n",
    "        print(f\"Warning: Found {len(df_processed[df_processed['NeededMeals'] < 0])} records with negative NeededMeals. Review filtering logic.\")\n",
    "        print(df_processed[df_processed['NeededMeals'] < 0][['OrderQty', 'CanceledQty', 'NeededMeals']].head())\n",
    "    else:\n",
    "        print(\"No negative 'NeededMeals' found after calculation, which is good.\")\n",
    "else:\n",
    "    print(\"Could not create 'NeededMeals' as 'OrderQty' or 'CanceledQty' is missing.\")"
   ],
   "id": "91788b25b730264b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating the target variable 'NeededMeals'...\n",
      "'NeededMeals' column created.\n",
      "Summary of 'NeededMeals':\n",
      "count    5.674222e+06\n",
      "mean     9.985110e-01\n",
      "std      4.098289e-01\n",
      "min      0.000000e+00\n",
      "25%      1.000000e+00\n",
      "50%      1.000000e+00\n",
      "75%      1.000000e+00\n",
      "max      1.200000e+02\n",
      "Name: NeededMeals, dtype: float64\n",
      "No negative 'NeededMeals' found after calculation, which is good.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T07:39:25.044115Z",
     "start_time": "2025-06-01T07:39:23.401866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nAddressing 'MenuName' variations (initial thoughts):\")\n",
    "if 'MenuName' in df_processed.columns:\n",
    "    unique_menu_names_count = df_processed['MenuName'].nunique()\n",
    "    print(f\"Number of unique 'MenuName' entries: {unique_menu_names_count}\")\n",
    "    if unique_menu_names_count > 50: # Just to show a few if there are many\n",
    "        print(\"First 20 unique menu names (sample):\")\n",
    "        print(df_processed['MenuName'].unique()[:20])\n",
    "    else:\n",
    "        print(\"Unique menu names:\")\n",
    "        print(df_processed['MenuName'].unique())\n",
    "\n",
    "    print(\"Strategy for MenuName standardization will be needed (e.g., lowercasing, removing extra spaces, fuzzy matching, or mapping). This is a significant task for later.\")\n",
    "    # Example of simple cleaning:\n",
    "    # df_processed['MenuName_Cleaned'] = df_processed['MenuName'].astype(str).str.lower().str.strip()\n",
    "    # print(f\"Number of unique 'MenuName_Cleaned' entries after basic cleaning: {df_processed['MenuName_Cleaned'].nunique()}\")\n",
    "else:\n",
    "    print(\"Warning: 'MenuName' column not found.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Initial Data Cleaning & Preprocessing Complete (Part 1) ---\")\n",
    "print(\"Cleaned DataFrame shape:\", df_processed.shape)\n",
    "print(\"\\nFirst 5 rows of the processed DataFrame:\")\n",
    "print(df_processed.head())\n",
    "print(\"\\nProcessed DataFrame info:\")\n",
    "df_processed.info(verbose=True, show_counts=True)"
   ],
   "id": "e433e7aadf89cb5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Addressing 'MenuName' variations (initial thoughts):\n",
      "Number of unique 'MenuName' entries: 322\n",
      "First 20 unique menu names (sample):\n",
      "['Mittagessen (Gs)' 'Smart Eating Buffet (WGrus)' 'Mittagessen (BS)'\n",
      " 'Smart Eating Buffet (Primus)' 'Menü A (HSS)'\n",
      " 'Smart Eating Buffet (GymBo)' 'Smart Eating Buffet (BRS)' 'Menü B1'\n",
      " 'Smart Eating Buffet (EMA)' 'Mittagessen (ML)'\n",
      " 'Smart-Eating Buffet (EGM)' 'DGE-MENÜ (MG)' 'Menü A (BO-Mitte)'\n",
      " 'Menü A (MarBi)' 'Smart Eating Buffet (GMA)' 'Mittagessen (BK)' 'Menü A'\n",
      " 'Menü A (SZG)' 'Salatbar (MPG)' 'Menü B2 (LUI)']\n",
      "Strategy for MenuName standardization will be needed (e.g., lowercasing, removing extra spaces, fuzzy matching, or mapping). This is a significant task for later.\n",
      "\n",
      "--- Initial Data Cleaning & Preprocessing Complete (Part 1) ---\n",
      "Cleaned DataFrame shape: (5674222, 15)\n",
      "\n",
      "First 5 rows of the processed DataFrame:\n",
      "    OrderId                     TransactionId DateOfService  \\\n",
      "0  11518978  4c5060636f584ef9a1effa77282755f5    2020-01-02   \n",
      "1  11285143  68472c70b9c84fb784834ecc257827d7    2020-01-02   \n",
      "2  11285146  7262eace0d104592b1269e38f5b45ec1    2020-01-02   \n",
      "3  11285152  8e451931e8fc4554869c3e4533b65e23    2020-01-02   \n",
      "4  11285155  bfa8fa0812ee40baa98e5aaf52d30e0b    2020-01-02   \n",
      "\n",
      "          DateOfOrder  OrderQty                     MenuName  MenuPrice  \\\n",
      "0 2020-02-05 11:54:08         1             Mittagessen (Gs)        310   \n",
      "1 2019-12-16 10:30:51         1  Smart Eating Buffet (WGrus)          0   \n",
      "2 2019-12-16 10:31:33         1  Smart Eating Buffet (WGrus)        290   \n",
      "3 2019-12-16 10:32:05         1  Smart Eating Buffet (WGrus)          0   \n",
      "4 2019-12-16 10:32:31         1  Smart Eating Buffet (WGrus)        290   \n",
      "\n",
      "   MenuSubsidy      BookingNr                       GroupName  CanceledQty  \\\n",
      "0            0   349-88220481        xxx3,45€ normal 5T (68€)            0   \n",
      "1          350  248-141751492          Steinfurt Abo ermäßigt            0   \n",
      "2           60   248-77489928  Westerkappeln Grundschüler Abo            0   \n",
      "3          350   248-77558043          Steinfurt Abo ermäßigt            0   \n",
      "4           60   248-77420774  Westerkappeln Grundschüler Abo            0   \n",
      "\n",
      "  DateOfCancel Site SchoolID  NeededMeals  \n",
      "0          NaT   LP   SCH001            1  \n",
      "1          NaT   BK   SCH002            1  \n",
      "2          NaT   BK   SCH002            1  \n",
      "3          NaT   BK   SCH002            1  \n",
      "4          NaT   BK   SCH002            1  \n",
      "\n",
      "Processed DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5674222 entries, 0 to 6538738\n",
      "Data columns (total 15 columns):\n",
      " #   Column         Non-Null Count    Dtype         \n",
      "---  ------         --------------    -----         \n",
      " 0   OrderId        5674222 non-null  int64         \n",
      " 1   TransactionId  5674222 non-null  object        \n",
      " 2   DateOfService  5674222 non-null  datetime64[ns]\n",
      " 3   DateOfOrder    5674222 non-null  datetime64[ns]\n",
      " 4   OrderQty       5674222 non-null  int64         \n",
      " 5   MenuName       5674222 non-null  object        \n",
      " 6   MenuPrice      5674222 non-null  int64         \n",
      " 7   MenuSubsidy    5674222 non-null  int64         \n",
      " 8   BookingNr      5674222 non-null  object        \n",
      " 9   GroupName      5674222 non-null  object        \n",
      " 10  CanceledQty    5674222 non-null  int64         \n",
      " 11  DateOfCancel   69962 non-null    datetime64[ns]\n",
      " 12  Site           5674222 non-null  object        \n",
      " 13  SchoolID       5674222 non-null  object        \n",
      " 14  NeededMeals    5674222 non-null  int64         \n",
      "dtypes: datetime64[ns](3), int64(6), object(6)\n",
      "memory usage: 692.7+ MB\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T08:01:25.784284Z",
     "start_time": "2025-06-01T08:01:25.736389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(df_processed.head())\n",
    "snapshot5_path = os.path.join(snapshot_dir, 'snapshot_5_after_basic_MenuName_cleaning.html')\n",
    "df_processed.head(rows_for_snapshot).to_html(snapshot5_path, escape=False, index=False)"
   ],
   "id": "f9c09d9b9850635a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    OrderId                     TransactionId DateOfService  \\\n",
      "0  11518978  4c5060636f584ef9a1effa77282755f5    2020-01-02   \n",
      "1  11285143  68472c70b9c84fb784834ecc257827d7    2020-01-02   \n",
      "2  11285146  7262eace0d104592b1269e38f5b45ec1    2020-01-02   \n",
      "3  11285152  8e451931e8fc4554869c3e4533b65e23    2020-01-02   \n",
      "4  11285155  bfa8fa0812ee40baa98e5aaf52d30e0b    2020-01-02   \n",
      "\n",
      "          DateOfOrder  OrderQty                     MenuName  MenuPrice  \\\n",
      "0 2020-02-05 11:54:08         1             Mittagessen (Gs)        310   \n",
      "1 2019-12-16 10:30:51         1  Smart Eating Buffet (WGrus)          0   \n",
      "2 2019-12-16 10:31:33         1  Smart Eating Buffet (WGrus)        290   \n",
      "3 2019-12-16 10:32:05         1  Smart Eating Buffet (WGrus)          0   \n",
      "4 2019-12-16 10:32:31         1  Smart Eating Buffet (WGrus)        290   \n",
      "\n",
      "   MenuSubsidy      BookingNr                       GroupName  CanceledQty  \\\n",
      "0            0   349-88220481        xxx3,45€ normal 5T (68€)            0   \n",
      "1          350  248-141751492          Steinfurt Abo ermäßigt            0   \n",
      "2           60   248-77489928  Westerkappeln Grundschüler Abo            0   \n",
      "3          350   248-77558043          Steinfurt Abo ermäßigt            0   \n",
      "4           60   248-77420774  Westerkappeln Grundschüler Abo            0   \n",
      "\n",
      "  DateOfCancel Site SchoolID  NeededMeals  \n",
      "0          NaT   LP   SCH001            1  \n",
      "1          NaT   BK   SCH002            1  \n",
      "2          NaT   BK   SCH002            1  \n",
      "3          NaT   BK   SCH002            1  \n",
      "4          NaT   BK   SCH002            1  \n"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

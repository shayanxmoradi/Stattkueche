{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40f0790-2d6c-44dd-8c6f-bbccdbfddd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 7. IN-DEPTH ANALYSIS AND VISUALIZATION ---\n",
    "print(\"\\n--- Step 7: In-Depth Analysis and Visualization ---\")\n",
    "# This new section provides deeper insights into model performance and predictions.\n",
    "\n",
    "# 7.1. Model Performance Summary Table\n",
    "print(\"\\n--- 7.1. Model Performance Summary ---\")\n",
    "performance_pivot = results_df.pivot(index='Site', columns='Horizon', values='Avg_Asymmetric_Loss')\n",
    "print(\"Average Asymmetric Loss by Site and Horizon:\")\n",
    "display(performance_pivot.style.background_gradient(cmap='Reds', axis=None).format(\"{:.2f}\"))\n",
    "\n",
    "# 7.2. Feature Importance Visualization\n",
    "print(\"\\n--- 7.2. Feature Importance Visualization ---\")\n",
    "# Visualize feature importances for a sample forecasting model (first site, 1-day horizon)\n",
    "sample_site = sites[0]\n",
    "sample_horizon = 'target_1_day'\n",
    "model_to_inspect = models[sample_site][sample_horizon]['model']\n",
    "features_to_inspect = models[sample_site][sample_horizon]['features']\n",
    "\n",
    "feature_importances_forecast = pd.DataFrame({\n",
    "    'feature': features_to_inspect,\n",
    "    'importance': model_to_inspect.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importances_forecast.head(15), palette='mako')\n",
    "plt.title(f'Top 15 Feature Importances for Forecasting\\n(Site: {sample_site}, Horizon: {sample_horizon})')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7.3. Prediction vs. Actuals Plots for All Sites\n",
    "print(\"\\n--- 7.3. Prediction vs. Actuals Plots ---\")\n",
    "print(\"Visualizing performance on the last cross-validation fold for the 1-day horizon.\")\n",
    "for site in sites:\n",
    "    test_data = all_test_sets[site]['target_1_day']\n",
    "    y_test = test_data['y_test']\n",
    "    y_pred = test_data['y_pred']\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(y_test.index, y_test, label='Actual Values', color='dodgerblue', alpha=0.8, marker='o', linestyle='-')\n",
    "    plt.plot(y_test.index, y_pred, label='Predicted Values', color='red', linestyle='--')\n",
    "    plt.title(f'Forecast vs. Actuals for {site} (1-Day Horizon)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Net Meal Quantity')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.show()\n",
    "\n",
    "# 7.4. Error Analysis\n",
    "print(\"\\n--- 7.4. Error Analysis ---\")\n",
    "# Analyze errors for a sample model (first site, 1-day horizon)\n",
    "sample_test_data = all_test_sets[sample_site][sample_horizon]\n",
    "errors = sample_test_data['y_test'] - sample_test_data['y_pred']\n",
    "\n",
    "# Plot 1: Error Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(errors, kde=True, bins=30)\n",
    "plt.axvline(x=0, color='red', linestyle='--', label='Zero Error')\n",
    "plt.title(f'Distribution of Prediction Errors\\n(Site: {sample_site}, Horizon: {sample_horizon})')\n",
    "plt.xlabel('Error (Actual - Predicted)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Errors Over Time\n",
    "plt.figure(figsize=(15, 6))\n",
    "errors.plot(label='Prediction Error', color='purple', alpha=0.8)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.title(f'Prediction Errors Over Time\\n(Site: {sample_site}, Horizon: {sample_horizon})')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Error')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- End of Analysis ---\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- 3. & 4. TIME SERIES CROSS-VALIDATION & MODEL TRAINING ---\n",
    "print(\"\\n--- Steps 3 & 4: Time Series Cross-Validation & Final Model Training ---\")\n",
    "\n",
    "sites = pivot_demand.columns\n",
    "models = {}\n",
    "evaluation_results = []\n",
    "reg_features = []  # Initialize empty list to store feature names\n",
    "all_test_sets = {}\n",
    "# Setup for TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "for site in sites:\n",
    "    print(f\"\\n--- Processing Site: {site} ---\")\n",
    "    models[site] = {}\n",
    "    all_test_sets[site] = {}\n",
    "\n",
    "    # Create site-specific features to prevent data leakage from other sites' futures\n",
    "    site_features = time_features.copy()\n",
    "    for lag in [1, 2, 3, 7, 14]:\n",
    "        site_features[f'site_lag_{lag}'] = pivot_demand[site].shift(lag)\n",
    "    site_features['site_rolling_mean_7'] = pivot_demand[site].shift(1).rolling(window=7).mean()\n",
    "    site_features['site_rolling_mean_14'] = pivot_demand[site].shift(1).rolling(window=14).mean()\n",
    "    site_features = site_features.ffill().bfill().fillna(0)  # Fill NaNs from shifts/rolls\n",
    "\n",
    "    # Store the list of all feature names *once* to ensure consistency\n",
    "    if not reg_features:\n",
    "        reg_features = site_features.columns.tolist()\n",
    "\n",
    "    for horizon_name, target_df in target_dfs.items():\n",
    "        print(f\"  Processing model for horizon: {horizon_name}\")\n",
    "\n",
    "        y_series = target_df[site]\n",
    "        # Align features and target, dropping rows where target is NaN\n",
    "        temp_df = pd.concat([site_features, y_series.rename('target')], axis=1)\n",
    "        temp_df.dropna(subset=['target'], inplace=True)\n",
    "        X = temp_df[reg_features]  # Ensure column order is consistent\n",
    "        y = temp_df['target']\n",
    "\n",
    "        # Perform Cross-Validation\n",
    "        mae_scores = []\n",
    "        print(f\"    Running {tscv.n_splits}-fold Time Series Cross-Validation...\")\n",
    "        for fold, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            rf_regressor_fold = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, min_samples_leaf=5)\n",
    "            rf_regressor_fold.fit(X_train, y_train)\n",
    "\n",
    "            y_pred_fold = rf_regressor_fold.predict(X_test)\n",
    "            mae = mean_absolute_error(y_test, y_pred_fold)\n",
    "            mae_scores.append(mae)\n",
    "\n",
    "        average_mae = np.mean(mae_scores)\n",
    "        std_mae = np.std(mae_scores)\n",
    "        print(f\"  > CV Average MAE for {horizon_name}: {average_mae:.2f} (+/- {std_mae:.2f})\")\n",
    "        evaluation_results.append(\n",
    "            {'Site': site, 'Horizon': horizon_name, 'Average_MAE': average_mae, 'Std_MAE': std_mae})\n",
    "\n",
    "        # Train the final model on ALL available data for this horizon\n",
    "        print(f\"  Training final model on {len(X)} data points...\")\n",
    "        final_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, min_samples_leaf=5)\n",
    "        final_model.fit(X, y)\n",
    "        models[site][horizon_name] = {'model': final_model}\n",
    "\n",
    "print(\"\\n--- End of Steps 3 & 4 ---\")\n"
   ],
   "id": "8907df601140b9af"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
